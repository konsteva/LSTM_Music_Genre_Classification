{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Genre Classification LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/konsteva/LSTM_Music_Genre_Classification/blob/main/Genre_Classification_LSTM.ipynb",
      "authorship_tag": "ABX9TyOwi/HNsLv5EUh/je0SK7p3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konsteva/LSTM_Music_Genre_Classification/blob/main/New_Copy_of_Genre_Classification_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgf8y2fXdjCK"
      },
      "source": [
        "# Check devices type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btFVzDTAJXuy"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "tf.test.gpu_device_name()\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vK3x5pFN0Wh"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HXUSgk4LN4i"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX0Q0Dx4I4EF"
      },
      "source": [
        "# Set up, Connect to Kaggle API and Download the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnv07_uYI3KP"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyXX6trmKqs_"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8gauSfJKrO8"
      },
      "source": [
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbd99yESKrme"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-aRAcJvNBsx"
      },
      "source": [
        "! kaggle datasets download andradaolteanu/gtzan-dataset-music-genre-classification\n",
        "! unzip /content/gtzan-dataset-music-genre-classification.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vds2R_l8b7YY"
      },
      "source": [
        "# Initializing parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkKWhExVb0fc"
      },
      "source": [
        "import math\n",
        "\n",
        "dataset_path = \"/content/Data/genres_original\"\n",
        "json_path = \"/content/extracted_data2.json\"\n",
        "sample_rate = 22050\n",
        "n_fft = 2048\n",
        "num_mfcc = 13\n",
        "hop_length = 512\n",
        "track_duration = 30  # measured in seconds\n",
        "samples_per_track = sample_rate * track_duration\n",
        "num_segments = 10\n",
        "samples_per_segment = int(samples_per_track / num_segments)\n",
        "num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoJIf6H3aTqp"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "import librosa\n",
        "\n",
        "# dictionary to save the extracted features\n",
        "data = {\n",
        "    \"mapping\": [],\n",
        "    \"labels\": [],\n",
        "    \"mfcc\": []\n",
        "}\n",
        "\n",
        "# loop through all genre sub-folder\n",
        "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "    # ensure we're processing a genre sub-folder level\n",
        "    if dirpath is not dataset_path:\n",
        "\n",
        "        # save genre label (i.e., sub-folder name) in the mapping\n",
        "        semantic_label = dirpath.split(\"\\\\\")[-1]\n",
        "        data[\"mapping\"].append(semantic_label)\n",
        "        print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # process all audio files in genre sub-dir\n",
        "        for f in filenames:\n",
        "                try:\n",
        "                    # load audio file\n",
        "                    file_path = os.path.join(dirpath, f)\n",
        "                    signal, sample_rate = librosa.load(file_path, sr=sample_rate)\n",
        "\n",
        "                    # process all segments of audio file\n",
        "                    for d in range(num_segments):\n",
        "\n",
        "                        # calculate start and finish sample for current segment\n",
        "                        start = samples_per_segment * d\n",
        "                        finish = start + samples_per_segment\n",
        "\n",
        "                        # extract mfcc\n",
        "                        mfcc = librosa.feature.mfcc(signal[start:finish], sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft,\n",
        "                                                    hop_length=hop_length)\n",
        "                        mfcc = mfcc.T\n",
        "\n",
        "                        # store only mfcc feature with expected number of vectors\n",
        "                        if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "                            data[\"mfcc\"].append(mfcc.tolist())\n",
        "                            data[\"labels\"].append(i - 1)\n",
        "                            print(\"{}, segment:{}\".format(file_path.split(\"\\\\\")[-1], d + 1))\n",
        "                except:\n",
        "                      print('Skipped song')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ11Sdscae_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb24de97-2820-4c43-932b-097d9d91abba"
      },
      "source": [
        "# save MFCCs to json file\n",
        "with open(json_path, \"w\") as fp:\n",
        "    print('Writing the data in the .json file. This might take several minutes!')\n",
        "    json.dump(data, fp, indent=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing the data in the .json file. This might take several minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrViFGA9d5RD"
      },
      "source": [
        "# Load and reform the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmzgF881c7WQ"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "json_path = \"/content/extracted_data2.json\"\n",
        "\n",
        "with open(json_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Make numpy arrays from dictionary\n",
        "# 3D arrays (song, sample ,MFCC)\n",
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"labels\"])\n",
        "\n",
        "# Split data (train=80%, test=20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)\n",
        "# Split data (train=60%, validation=20%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)\n",
        "\n",
        "\n",
        "input_shape = X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Qw8F6veNLm"
      },
      "source": [
        "# Build and save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vBl9dcWc97E"
      },
      "source": [
        "import keras\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from keras.models import load_model\n",
        "\n",
        "model = keras.Sequential()\n",
        "# Input Layer\n",
        "model.add(LSTM(128,input_shape=input_shape))\n",
        "model.add(Dropout(0.2))\n",
        "# 1st Hidden Layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# 2nd Hidden Layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "# 3rd Hidden Layer\n",
        "model.add(Dense(48, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "# Output Layer\n",
        "model.add(Dense(24, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', loss='SparseCategoricalCrossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=150, batch_size=20, validation_data=(X_val, y_val), shuffle=False)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "model_name = 'Genre_model.h5'\n",
        "model.save(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG9_nD2XeSKB"
      },
      "source": [
        "# Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSnmpVMVc-Rg"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Plot train and validation set accuracy\n",
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Plot')\n",
        "plt.legend()\n",
        "\n",
        "# Plot train and validation set error\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error')\n",
        "plt.title('Error Plot')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}